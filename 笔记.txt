实现word2vec的训练模型，产生最终的词向量

步骤
1.数据预处理
     文本分词：将文本数据分割成单词或词组
     去除停用词：移除常见但无意义的词语
     构建词汇表：创建一个包含所有唯一单词的列表或者独立的词典对象
     生成训练样本：根据上下文窗口大小，生成中心词和上下文词对（和模型有关）
2.模型选择和构建
        选择模型架构：CBOW（Continuous Bag of Words）或Skip-gram
        定义模型结构：输入层、隐藏层和输出层的神经网络结构
3.模型训练
        初始化参数：随机初始化权重和偏置
        前向传播：计算输入通过网络的输出
        计算损失：使用适当的损失函数（如交叉熵损失）计算预测值与真实值之间的差异
        反向传播：计算梯度并更新模型参数（使用优化算法如SGD或Adam）
        迭代训练：重复前向传播、计算损失和反向传播多个epoch，直到模型收敛